import asyncio
import os
import re
import datetime
from dataclasses import dataclass
from typing import Any, Callable, Optional
import discord
from src.logger import get_logger

logger = get_logger(__name__)

@dataclass
class LLMJob:
    type: str  # 'summary', 'deep_dive', 'ask', 'weekly'
    payload: Any
    context: Optional[discord.Message] = None
    on_complete: Optional[Callable] = None

class LLMQueue:
    def __init__(self, bot):
        from src.config import LLM_CONCURRENCY, OUTPUT_CHANNEL_ID
        self.bot = bot
        self.queue = asyncio.Queue()
        self.is_running = True
        self.concurrency = LLM_CONCURRENCY
        self.output_channel_id = OUTPUT_CHANNEL_ID

    def qsize(self):
        return self.queue.qsize()

    def start(self):
        """ì„¤ì •ëœ ë™ì‹œì„±ë§Œí¼ ì›Œì»¤ ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        logger.info(f"[Queue] ì›Œì»¤ ì‹œì‘ (Concurrency: {self.concurrency})")
        for i in range(self.concurrency):
            self.bot.loop.create_task(self.worker(i + 1))

    async def add_job(self, job: LLMJob):
        await self.queue.put(job)
        if job.context:
            try:
                await job.context.add_reaction("â³")
            except: pass
        logger.info(f"[Queue] ì‘ì—… ì¶”ê°€ë¨: {job.type}. ëŒ€ê¸°ì—´ í¬ê¸°: {self.queue.qsize()}")

    async def worker(self, worker_id):
        logger.info(f"[Queue] Worker-{worker_id} ì‹œì‘.")
        while self.is_running:
            job = await self.queue.get()
            logger.info(f"[Queue][Worker-{worker_id}] ì‘ì—… ì²˜ë¦¬ ì‹œì‘: {job.type}")
            
            try:
                if job.context:
                    try:
                        await job.context.remove_reaction("â³", self.bot.user)
                        await job.context.add_reaction("ğŸ”„")
                    except: pass

                if job.type == 'summary':
                    await self._process_summary(job)
                elif job.type == 'deep_dive':
                    await self._process_deep_dive(job)
                elif job.type == 'ask':
                    await self._process_ask(job)
                elif job.type == 'weekly':
                    await self._process_weekly(job)
                
                logger.info(f"[Queue][Worker-{worker_id}] ì‘ì—… ì™„ë£Œ: {job.type}")
                if job.context:
                    try:
                        await job.context.remove_reaction("ğŸ”„", self.bot.user)
                        await job.context.add_reaction("âœ…")
                    except: pass

            except Exception as e:
                logger.error(f"[Queue][Worker-{worker_id}] ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({job.type})", exc_info=True)
                if job.context:
                    try:
                        await job.context.remove_reaction("ğŸ”„", self.bot.user)
                        await job.context.add_reaction("âŒ")
                        await job.context.channel.send(f"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    except: pass
            finally:
                self.queue.task_done()

    async def _process_summary(self, job):
        # payload: {'content': str, 'url': str, 'source_type': str}
        payload = job.payload
        logger.info(f"[_process_summary] LLM ë¶„ì„ ìš”ì²­ ì‹œì‘ (ê¸¸ì´: {len(payload['content'])})")
        analysis = await asyncio.to_thread(self.bot.ai.analyze, payload['content'])
        logger.info("[_process_summary] LLM ë¶„ì„ ì™„ë£Œ")
        
        if analysis:
            await self.bot._save_and_upload(analysis, payload['url'], payload['source_type'], job.context)
        else:
            raise Exception("AI ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    async def _process_deep_dive(self, job):
        # payload: {'content': str, 'url': str}
        import re, datetime, os
        from src.config import SAVE_DIR
        
        payload = job.payload
        logger.info(f"[_process_deep_dive] LLM ì‹¬ì¸µ ë¶„ì„ ìš”ì²­ ì‹œì‘ (ê¸¸ì´: {len(payload['content'])})")
        deep_analysis = await asyncio.to_thread(self.bot.ai.deep_dive, payload['content'])
        logger.info("[_process_deep_dive] LLM ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ")

        if not deep_analysis:
            raise Exception("AI ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        date_str = datetime.datetime.now().strftime("%Y-%m-%d")
        title_match = re.search(r'^#\s+(.+)', deep_analysis)
        title = title_match.group(1).strip() if title_match else "DeepDive"
        safe_title = re.sub(r'[\\/*?:"<>|]', "", title)
        
        # Determine Topic for Folder (Analyze title/content implicitly or just use default)
        # Deep Dive typically doesn't have explicit tags in payload, so we use title keywords
        from src.services.tag_manager import TagManager
        tm = TagManager()
        topic = tm.get_primary_topic(title.split())
        
        save_path = os.path.join(SAVE_DIR, topic)
        if not os.path.exists(save_path): os.makedirs(save_path)
        
        filename = f"{date_str}_[DeepDive]_{safe_title}.md"
        filepath = os.path.join(save_path, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"{deep_analysis}\n\n---\n**Source:** {payload['url']}")
        logger.info(f"[_process_deep_dive] íŒŒì¼ ì €ì¥ë¨: {filename}")

        # Blocking I/O
        uploaded = await asyncio.to_thread(self.bot.uploader.upload, filepath, title)
        drive_msg = "ğŸ“‚ **Drive ì—…ë¡œë“œ ì™„ë£Œ**" if uploaded else "âš ï¸ **Drive ì‹¤íŒ¨**"

        # ê²°ê³¼ ì±„ë„ë¡œ ì „ì†¡ (ì„œë¨¸ë¦¬ ì±„ë„)
        out_channel = self.bot.get_channel(self.output_channel_id)
        if out_channel:
            if len(deep_analysis) > 1900:
                preview = deep_analysis[:1000] + "\n\n...(ì¤‘ëµ)..."
                await out_channel.send(f"âœ… **[Deep Dive] ë¶„ì„ ì™„ë£Œ** ({drive_msg})\níŒŒì¼ëª…: `{filename}`\nì›ë³¸: {payload['url']}\n\n{preview}")
            else:
                await out_channel.send(f"âœ… **[Deep Dive] ë¶„ì„ ì™„ë£Œ** ({drive_msg})\nì›ë³¸: {payload['url']}\n\n{deep_analysis}")

        # ìš”ì²­ ì±„ë„(ë§í¬ ê³µìœ  ì±„ë„)ì—ëŠ” ì™„ë£Œ ì•Œë¦¼ ë° í ìƒíƒœ ì „ì†¡
        await job.context.channel.send(f"âœ… **Deep Dive ì™„ë£Œ** (ì„œë¨¸ë¦¬ ì±„ë„ í™•ì¸)\nğŸ“‰ ë‚¨ì€ ì‘ì—…: {self.queue.qsize()}ê°œ")

    async def _process_ask(self, job):
        # payload: {'query': str, 'docs': list}
        payload = job.payload
        logger.info(f"[_process_ask] ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {payload['query']}")
        try:
            system_prompt = "Answer the question based strictly on the provided Context. Answer in Korean."
            resp_content = await asyncio.to_thread(self.bot.ai.chat, messages=[
                {"role": "user", "content": f"{system_prompt}\n\n---Context:\n{''.join(payload['docs'][:5])}\n\nQ: {payload['query']}"}
            ], temperature=0.1)
            
            if not resp_content:
                raise Exception("AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨ (Empty response)")
                
            logger.info("[_process_ask] ë‹µë³€ ìƒì„± ì™„ë£Œ")
            await job.context.channel.send(f"ğŸ’¡ **ë‹µë³€:**\n{resp_content}")
        except Exception as e:
            raise Exception(f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")

    async def _process_weekly(self, job):
        # payload: {'context_text': str}
        import datetime, os
        from src.config import SAVE_DIR

        payload = job.payload
        logger.info("[_process_weekly] ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        try:
            system_prompt = "Summarize user's weekly tech learning trends in Korean. Group by topics."
            report = await asyncio.to_thread(self.bot.ai.chat, messages=[
                {"role": "user", "content": f"{system_prompt}\n\n---Articles:\n{payload['context_text']}"}
            ], temperature=0.3)

            if not report:
                raise Exception("AI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ (Empty response)")
            logger.info("[_process_weekly] ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            
            today = datetime.datetime.now()
            filename = f"Weekly_Report_{today.strftime('%Y%m%d')}.md"
            filepath = os.path.join(SAVE_DIR, filename)
            with open(filepath, "w", encoding='utf-8') as f: f.write(report)
            
            await asyncio.to_thread(self.bot.uploader.upload, filepath, "Weekly Report")
            
            if len(report) > 1900:
                await job.context.channel.send(f"âœ… **ì£¼ê°„ ë¦¬í¬íŠ¸ ì™„ë£Œ!** (íŒŒì¼ ë° ë“œë¼ì´ë¸Œ ì €ì¥ë¨)")
            else:
                await job.context.channel.send(f"ğŸ“Š **ì£¼ê°„ íŠ¸ë Œë“œ**\n{report}")
        except Exception as e:
            raise Exception(f"ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
