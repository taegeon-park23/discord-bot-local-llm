import discord
import os
import re
import asyncio
import datetime
import glob
import aiohttp
from src.logger import get_logger, LOG_FILE

logger = get_logger(__name__)

from src.config import (
    DISCORD_TOKEN, INPUT_CHANNEL_ID, OUTPUT_CHANNEL_ID, 
    MANAGEMENT_CHANNEL_ID, SAVE_DIR
)
from src.services.drive_handler import DriveUploader
from src.services.content_extractor import ContentExtractor
from src.services.ai_handler import AIAgent
from src.services.llm_queue import LLMQueue, LLMJob

class KnowledgeBot(discord.Client):
    def __init__(self):
        intents = discord.Intents.default()
        intents.message_content = True
        intents.reactions = True
        super().__init__(intents=intents)
        self.extractor = ContentExtractor()
        self.ai = AIAgent()
        self.uploader = DriveUploader()
        self.queue = LLMQueue(self)
        if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)

    async def on_ready(self):
        logger.info(f'Logged in as {self.user}')
        # Start LLM Queue Worker
        self.queue.start()
        await self.send_ngrok_url(MANAGEMENT_CHANNEL_ID, initial=True)

    async def get_ngrok_url(self):
        candidate_urls = ["http://ngrok_tunnel:4040/api/tunnels", "http://host.docker.internal:4040/api/tunnels"]
        logger.info("[Ngrok] URL íƒìƒ‰ ì‹œì‘...")
        for url in candidate_urls:
            try:
                logger.info(f"[Ngrok] ì ‘ì† ì‹œë„: {url}")
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=2) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            if data.get('tunnels'):
                                public_url = data['tunnels'][0]['public_url']
                                logger.info(f"[Ngrok] âœ… ì„±ê³µ: {public_url}")
                                return public_url
            except: pass
        return None

    async def send_ngrok_url(self, channel_id, initial=False):
        channel = self.get_channel(channel_id)
        if not channel: return
        url = await self.get_ngrok_url()
        if url:
            msg = f"ğŸš€ **ì§€ì‹ ì €ì¥ì†Œ & ë“œë¼ì´ë¸Œ ì—°ë™ ì¤‘!**\nì ‘ì†: {url}" if initial else f"ğŸŒ **ì£¼ì†Œ:**\n{url}"
            await channel.send(msg)
        elif not initial:
            await channel.send("âš ï¸ Ngrok í„°ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    async def on_raw_reaction_add(self, payload):
        if payload.user_id == self.user.id: return
        
        target_emojis = ["ğŸ•µï¸â€â™‚ï¸", "ğŸ•µï¸", "ğŸ•µ", "ğŸ”"]
        if str(payload.emoji) in target_emojis:
            channel = self.get_channel(payload.channel_id)
            if not channel: return
            try: message = await channel.fetch_message(payload.message_id)
            except: return

            url_match = re.search(r'(https?://\S+)', message.content)
            target_url = url_match.group(0) if url_match else (message.embeds[0].url if message.embeds else None)
            if not target_url: return

            await channel.send(f"ğŸ•µï¸â€â™‚ï¸ **Deep Dive ì‹œì‘...** (ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ í¬í•¨ / í ëŒ€ê¸° ê°€ëŠ¥)")
            try:
                data = await self.extractor.extract(target_url)
                if "error" in data:
                    logger.warning(f"ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨: {data['error']}")
                    await channel.send(f"âš ï¸ ì¶”ì¶œ ì‹¤íŒ¨: {data['error']}")
                    return

                await self.queue.add_job(LLMJob(
                    type='deep_dive',
                    payload={'content': data['content'], 'url': target_url},
                    context=message
                ))
            except Exception as e:
                logger.error(f"Deep Dive ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                await channel.send(f"âŒ ì˜¤ë¥˜: {e}")

    async def on_message(self, message):
        if message.author == self.user: return

        if message.channel.id == MANAGEMENT_CHANNEL_ID:
            if "!url" in message.content or "ì£¼ì†Œ" in message.content:
                await self.send_ngrok_url(message.channel.id)
            elif message.content.startswith("!weekly"):
                await self._handle_weekly_report(message)
            elif message.content.startswith("!ask"):
                await self._handle_ask_question(message)
            elif message.content.startswith("!log"):
                await self._handle_log_request(message)
            return

        if message.channel.id == INPUT_CHANNEL_ID:
            await self._handle_link_submission(message)

    async def _handle_weekly_report(self, message):
        logger.info("ì£¼ê°„ ë¦¬í¬íŠ¸ ìš”ì²­ ìˆ˜ì‹ ")
        await message.channel.send("ğŸ“… **ì£¼ê°„ ë¦¬í¬íŠ¸** ìƒì„± ì¤‘...")
        report_files = []
        today = datetime.datetime.now()
        files = glob.glob(os.path.join(SAVE_DIR, "*.md"))
        
        for f in files:
            if "[DeepDive]" in f: continue
            try:
                file_date = datetime.datetime.strptime(os.path.basename(f)[:10], "%Y-%m-%d")
                if (today - file_date).days <= 7:
                    with open(f, 'r', encoding='utf-8') as rf:
                        content = rf.read()
                        if "## ğŸ“ 3ì¤„ ìš”ì•½" in content:
                            summary = content.split("## ğŸ“ 3ì¤„ ìš”ì•½")[1].split("##")[0].strip()
                            report_files.append(f"- **{os.path.basename(f)[11:-3]}**:\n{summary}")
            except: continue

        if not report_files:
            await message.channel.send("âš ï¸ ìµœê·¼ 7ì¼ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        context_text = "\n\n".join(report_files)
        await self.queue.add_job(LLMJob(
            type='weekly',
            payload={'context_text': context_text},
            context=message
        ))

    async def _handle_ask_question(self, message):
        query = message.content.replace("!ask", "").strip()
        if not query:
            await message.channel.send("ì‚¬ìš©ë²•: `!ask <ì§ˆë¬¸>`")
            return
        
        logger.info(f"ì§ˆë¬¸ ìš”ì²­ ìˆ˜ì‹ : {query}")
        await message.add_reaction("ğŸ¤”")
        files = glob.glob(os.path.join(SAVE_DIR, "*.md"))
        docs = []
        for f in files:
            try:
                with open(f, 'r', encoding='utf-8') as rf:
                    content = rf.read()
                    if query in content or any(t in content for t in query.split()):
                        docs.append(f"Source: {os.path.basename(f)}\nContent: {content[:1000]}...")
            except: continue
        
        if not docs:
            await message.channel.send("âš ï¸ ê´€ë ¨ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
            await message.remove_reaction("ğŸ¤”", self.user)
            return

        await self.queue.add_job(LLMJob(
            type='ask',
            payload={'query': query, 'docs': docs},
            context=message
        ))
        await message.remove_reaction("ğŸ¤”", self.user)

    async def _handle_log_request(self, message):
        """!log [--lines] ëª…ë ¹ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        lines_to_read = 100
        args = message.content.split()
        for arg in args:
            if arg.startswith("--"):
                try:
                    lines_to_read = int(arg[2:])
                except: pass
        
        if not os.path.exists(LOG_FILE):
            await message.channel.send("âš ï¸ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        try:
            # ë§ˆì§€ë§‰ Nì¤„ ì½ê¸°
            with open(LOG_FILE, "r", encoding="utf-8") as f:
                # íš¨ìœ¨ì ì¸ tail êµ¬í˜„ (deque ì‚¬ìš©)
                from collections import deque
                lines = deque(f, maxlen=lines_to_read)
                log_content = "".join(lines)
            
            if not log_content:
                await message.channel.send("âš ï¸ ë¡œê·¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return

            # ë‚´ìš©ì´ ì§§ìœ¼ë©´ ë©”ì‹œì§€ë¡œ, ê¸¸ë©´ íŒŒì¼ë¡œ ì „ì†¡
            if len(log_content) < 1900:
                await message.channel.send(f"ğŸ“‹ **ìµœê·¼ ë¡œê·¸ ({len(lines)} lines):**\n```log\n{log_content}```")
            else:
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                temp_log_path = os.path.join(SAVE_DIR, f"log_tail_{lines_to_read}.txt")
                with open(temp_log_path, "w", encoding="utf-8") as f:
                    f.write(log_content)
                
                await message.channel.send(
                    f"ğŸ“‹ **ìµœê·¼ ë¡œê·¸ ({len(lines)} lines)**", 
                    file=discord.File(temp_log_path)
                )
                # ì „ì†¡ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(temp_log_path)

        except Exception as e:
            logger.error(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            await message.channel.send(f"âŒ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    async def _handle_link_submission(self, message):
        url_match = re.search(r'(https?://\S+)', message.content)
        if not url_match: return
        target_url = url_match.group(0)
        
        logger.info(f"ë§í¬ ìˆ˜ì‹ : {target_url}")

        await message.add_reaction("ğŸ‘€")
        try:
            data = await self.extractor.extract(target_url)
            if "error" in data:
                logger.warning(f"ë§í¬ ì¶”ì¶œ ì‹¤íŒ¨: {data['error']}")
                await message.channel.send(f"âš ï¸ {data['error']}")
                await message.remove_reaction("ğŸ‘€", self.user)
                return

            clean_url = self.extractor.normalize_url(target_url)
            await self.queue.add_job(LLMJob(
                type='summary',
                payload={'content': data['content'], 'url': clean_url, 'source_type': data['type']},
                context=message
            ))
        except Exception as e:
            logger.error(f"ë§í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            await message.channel.send(f"Error: {e}")
            await message.remove_reaction("ğŸ‘€", self.user)

    async def _save_and_upload(self, data, url, source_type, message):
        date_str = datetime.datetime.now().strftime("%Y-%m-%d")
        safe_title = re.sub(r'[\\/*?:"<>|]', "", data.get('title', 'Untitled'))
        filename = f"{date_str}_{safe_title}.md"
        filepath = os.path.join(SAVE_DIR, filename)
        
        summary = "\n".join([f"- {s}" for s in data.get('summary', [])]) if isinstance(data.get('summary'), list) else str(data.get('summary'))
        content = f"---\ntitle: \"{data.get('title')}\"\ndate: {date_str}\ncategory: {data.get('category')}\nurl: {url}\n---\n# {data.get('title')}\n\n## ğŸ“ 3ì¤„ ìš”ì•½\n{summary}\n\n## ğŸ”— ì›ë³¸\n{url} ({source_type})"
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)

        # Blocking I/Oë¥¼ ë³„ë„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ì°¨ë‹¨ ë°©ì§€
        await asyncio.to_thread(self.uploader.upload, filepath, data.get('title'))

        await message.remove_reaction("ğŸ‘€", self.user)
        await message.add_reaction("âœ…")
        
        out_ch = self.get_channel(OUTPUT_CHANNEL_ID)
        if out_ch:
            embed = discord.Embed(title=data.get('title'), url=url, color=0x00ff00)
            embed.add_field(name="ìš”ì•½", value=summary, inline=False)
            embed.set_footer(text=f"Local LLM â€¢ Drive Uploaded â€¢ Remaining: {self.queue.qsize()}")
            await out_ch.send(embed=embed)

        # ìš”ì²­ ì±„ë„ì— ë‚¨ì€ ì‘ì—… ìˆ˜ ì•Œë¦¼
        await message.channel.send(f"ğŸ“‰ ë‚¨ì€ ì‘ì—…: {self.queue.qsize()}ê°œ")
